{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dq6nJ4JIpaxE"
   },
   "source": [
    "# RemBG ‚Äî Naive Video Background Removal Pipeline\n",
    "\n",
    "## What this notebook demonstrates\n",
    "\n",
    "This notebook removes the background from every frame of a video using **rembg**, a library built on top of neural segmentation models.\n",
    "\n",
    "### How background removal works\n",
    "\n",
    "Traditional background removal (like green screens) relies on a known, uniform colour.  \n",
    "AI-based removal works differently: a neural network looks at the whole image and predicts which pixels belong to the *foreground subject* (a person, object, etc.) and which belong to the *background*. This is called **salient object detection**.\n",
    "\n",
    "The default model used here is **U2Net** (Qin et al., 2020). It was trained on large datasets of images with annotated foregrounds and learns to produce a soft *alpha mask* ‚Äî a grayscale image where white = keep and black = remove. The mask is then applied to the original frame to produce a transparent PNG.\n",
    "\n",
    "### Why \"naive\"?\n",
    "\n",
    "Each frame is processed **independently** ‚Äî the model has no memory of the previous frame. This means that even tiny differences in lighting or subject position cause the mask to shift slightly between frames, producing visible **flickering or jitter** in the output video.\n",
    "\n",
    "This is an intentional limitation of this demonstrator. Fixing it requires **temporal consistency** techniques (e.g. optical flow, cross-frame attention) explored in other notebooks.\n",
    "\n",
    "**Steps in this notebook:**\n",
    "1. Install dependencies\n",
    "2. Create working folders\n",
    "3. Upload a video\n",
    "4. Extract frames with FFmpeg\n",
    "5. Apply RemBG to each frame individually\n",
    "6. Reassemble frames into a video\n",
    "7. Observe the flickering artefact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî Install dependencies\n",
    "\n",
    "| Package | Role |\n",
    "|---|---|\n",
    "| `rembg` | Background removal library. Wraps the U2Net model and exposes a simple `remove()` function. |\n",
    "| `ffmpeg-python` | Python bindings for FFmpeg. Used to extract frames from a video and reassemble them afterwards. |\n",
    "| `onnxruntime` | Runtime engine for ONNX models. U2Net is distributed as an `.onnx` file, which `rembg` downloads automatically on first use. ONNX (Open Neural Network Exchange) is a portable model format that runs on CPU or GPU without requiring a specific training framework like PyTorch. |\n",
    "\n",
    "> **GPU note:** By default `onnxruntime` runs on CPU. Installing `onnxruntime-gpu` instead enables CUDA acceleration and speeds up processing significantly on longer videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8351,
     "status": "ok",
     "timestamp": 1744204209371,
     "user": {
      "displayName": "Eduardo",
      "userId": "02969445285498016452"
     },
     "user_tz": -120
    },
    "id": "I8ZSKEcrpaxF",
    "outputId": "4367d527-76ac-4829-83c1-6b89ca42b67a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rembg in /usr/local/lib/python3.11/dist-packages (2.0.65)\n",
      "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from rembg) (4.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rembg) (2.0.2)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from rembg) (4.11.0.86)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from rembg) (11.1.0)\n",
      "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from rembg) (1.8.2)\n",
      "Requirement already satisfied: pymatting in /usr/local/lib/python3.11/dist-packages (from rembg) (1.1.13)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from rembg) (0.25.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from rembg) (1.14.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from rembg) (4.67.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (2.32.3)\n",
      "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.11/dist-packages (from pymatting->rembg) (0.60.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.43.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->rembg) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (2025.1.31)\n",
      "Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.0\n",
      "Requirement already satisfied: rembg in /usr/local/lib/python3.11/dist-packages (2.0.65)\n",
      "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from rembg) (4.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rembg) (2.0.2)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from rembg) (4.11.0.86)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from rembg) (11.1.0)\n",
      "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from rembg) (1.8.2)\n",
      "Requirement already satisfied: pymatting in /usr/local/lib/python3.11/dist-packages (from rembg) (1.1.13)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from rembg) (0.25.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from rembg) (1.14.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from rembg) (4.67.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (4.3.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (24.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (2.32.3)\n",
      "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.11/dist-packages (from pymatting->rembg) (0.60.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (0.4)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.43.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->rembg) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (2025.1.31)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Install dependencies\n",
    "%pip install rembg ffmpeg-python onnxruntime\n",
    "%pip install rembg ffmpeg-python\n",
    "%apt-get install -y ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Create working folders\n",
    "\n",
    "We work with individual image files rather than the video directly, so we need two staging folders:\n",
    "\n",
    "- `frames/` ‚Äî raw frames extracted from the input video\n",
    "- `output_frames/` ‚Äî frames after background removal\n",
    "\n",
    "Both are temporary; they are not the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgWxq-v9paxG"
   },
   "outputs": [],
   "source": [
    "# üìÅ Create folders\n",
    "import os\n",
    "for folder in [\"frames\", \"output_frames\"]:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî Upload your video\n",
    "\n",
    "This cell uses the Colab file uploader. Upload an MP4 or MOV clip ‚Äî **shorter clips (5‚Äì15 seconds) are recommended** to keep processing time reasonable on CPU.\n",
    "\n",
    "**Tips for best results:**\n",
    "- The subject should be clearly separated from the background (e.g. a person against a wall).\n",
    "- Avoid very busy or textured backgrounds ‚Äî U2Net can struggle with complex scenes.\n",
    "- Consistent lighting across the clip reduces mask instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 28881,
     "status": "ok",
     "timestamp": 1744204069762,
     "user": {
      "displayName": "Eduardo",
      "userId": "02969445285498016452"
     },
     "user_tz": -120
    },
    "id": "xTGNsO03paxG",
    "outputId": "5a2e61bd-3c91-4149-93b6-dbe79b6ce843"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-bdc74306-117b-4d36-b30f-12966ad50ef8\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-bdc74306-117b-4d36-b30f-12966ad50ef8\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 20250409_1305_Gentle Dance Breeze_simple_compose_01jrd3jwyefq7v0vbypcqm82w9.mp4 to 20250409_1305_Gentle Dance Breeze_simple_compose_01jrd3jwyefq7v0vbypcqm82w9.mp4\n"
     ]
    }
   ],
   "source": [
    "# ‚¨ÜÔ∏è Upload your video\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 ‚Äî Extract frames from the video\n",
    "\n",
    "A video is just a sequence of still images (frames) displayed in rapid succession (typically 24‚Äì60 frames per second). To process it with a per-image model we must:\n",
    "\n",
    "1. **Decode** the video into individual frames ‚Äî FFmpeg reads the compressed video stream and outputs one PNG file per frame.\n",
    "2. **Process** each frame.\n",
    "3. **Re-encode** the processed frames back into a video.\n",
    "\n",
    "`qscale=2` sets FFmpeg's JPEG-like quality scale for PNG export. Lower values = higher quality (range 1‚Äì31). We use 2 to preserve fine detail in hair and edges that the model needs to segment accurately.\n",
    "\n",
    "> The frame filenames (`frame_00001.png`, `frame_00002.png`, ‚Ä¶) encode the order. This ordering is essential when reassembling the video later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7018,
     "status": "ok",
     "timestamp": 1744204080641,
     "user": {
      "displayName": "Eduardo",
      "userId": "02969445285498016452"
     },
     "user_tz": -120
    },
    "id": "vflwTeskpaxG",
    "outputId": "00c0fac2-b68f-46db-a0b2-2485018b9dfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üéûÔ∏è Extract frames from the video\n",
    "import ffmpeg\n",
    "\n",
    "input_video = list(uploaded.keys())[0]\n",
    "(\n",
    "    ffmpeg\n",
    "    .input(input_video)\n",
    "    .output('frames/frame_%05d.png', qscale=2)\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 ‚Äî Apply background removal frame by frame\n",
    "\n",
    "`rembg.remove()` takes raw image bytes and returns a PNG with an **alpha channel** added. The alpha channel is a fourth pixel channel (RGBA) that controls transparency:\n",
    "- **255 (white)** = fully opaque ‚Äî this pixel belongs to the foreground subject.\n",
    "- **0 (black)** = fully transparent ‚Äî this pixel is background and should be discarded.\n",
    "- Values in between produce soft, semi-transparent edges (important for hair and fur).\n",
    "\n",
    "Internally, `remove()`:\n",
    "1. Resizes the image to the model's input resolution.\n",
    "2. Runs a forward pass through U2Net, producing a probability map (the \"saliency map\").\n",
    "3. Post-processes the map into a binary-ish mask with soft edges.\n",
    "4. Applies the mask to the original image as an alpha channel.\n",
    "\n",
    "On first run the model weights (`u2net.onnx`, ~176 MB) are downloaded and cached in `~/.u2net/`. Subsequent runs use the cache.\n",
    "\n",
    "> **Performance note:** Each frame is an independent model call. For a 30 fps, 10-second clip that is 300 inference passes. This is why GPU acceleration matters for real-time or near-real-time use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383950,
     "status": "ok",
     "timestamp": 1744204601616,
     "user": {
      "displayName": "Eduardo",
      "userId": "02969445285498016452"
     },
     "user_tz": -120
    },
    "id": "Y9CoMw71paxG",
    "outputId": "ca22469d-70ec-4ebf-d5af-06851d2e6ae0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176M/176M [00:00<00:00, 186GB/s]\n"
     ]
    }
   ],
   "source": [
    "# ‚úÇÔ∏è Apply RemBG frame-by-frame\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "input_dir = \"frames\"\n",
    "output_dir = \"output_frames\"\n",
    "\n",
    "for filename in sorted(os.listdir(input_dir)):\n",
    "    if filename.endswith(\".png\"):\n",
    "        with open(os.path.join(input_dir, filename), \"rb\") as inp:\n",
    "            input_data = inp.read()\n",
    "            output_data = remove(input_data)\n",
    "        with open(os.path.join(output_dir, filename), \"wb\") as out:\n",
    "            out.write(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Inspect a single frame ‚Äî before and after background removal\n",
    "# This cell visualises the alpha mask alongside the original and processed frame.\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "sample_file = sorted(os.listdir(\"frames\"))[0]\n",
    "\n",
    "original = Image.open(f\"frames/{sample_file}\").convert(\"RGB\")\n",
    "processed = Image.open(f\"output_frames/{sample_file}\").convert(\"RGBA\")\n",
    "\n",
    "# The alpha channel is the mask predicted by U2Net\n",
    "alpha_mask = processed.split()[-1]  # Extract alpha channel as greyscale image\n",
    "\n",
    "# Composite the processed frame over a white background so transparency is visible\n",
    "white_bg = Image.new(\"RGB\", processed.size, (255, 255, 255))\n",
    "white_bg.paste(processed, mask=alpha_mask)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(original);       axes[0].set_title(\"Original frame\")\n",
    "axes[1].imshow(alpha_mask, cmap=\"gray\"); axes[1].set_title(\"Alpha mask (U2Net output)\")\n",
    "axes[2].imshow(white_bg);       axes[2].set_title(\"Result (composited on white)\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(f\"Frame: {sample_file}\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 ‚Äî Reassemble the video\n",
    "\n",
    "FFmpeg reads the numbered PNGs in order and encodes them into an MP4:\n",
    "\n",
    "- **`vcodec=libx264`** ‚Äî H.264, the most widely compatible video codec. Works in browsers, phones, and every video player.\n",
    "- **`pix_fmt=yuv420p`** ‚Äî the pixel format expected by H.264. It does **not** support an alpha channel, so the transparency from rembg is composited over **black** in the output. To preserve transparency you would use `libvpx-vp9` with `yuva420p` and output a `.webm` file.\n",
    "- **`framerate=30`** ‚Äî must match the framerate used during extraction, otherwise the video plays at the wrong speed.\n",
    "\n",
    "> **Watch for flickering.** Play the output video and notice how the mask boundary shifts between frames. This is the core artefact of frame-independent processing. Compare it to your input and ask yourself: what information from adjacent frames could the model use to stabilise the mask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171,
     "resources": {
      "http://localhost:8080/output.mp4": {
       "data": "",
       "headers": [
        [
         "content-length",
         "0"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 4229,
     "status": "ok",
     "timestamp": 1744204659518,
     "user": {
      "displayName": "Eduardo",
      "userId": "02969445285498016452"
     },
     "user_tz": -120
    },
    "id": "q3b-lStGpaxH",
    "outputId": "668bf724-2bae-48cc-9575-15a292c5532c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"output.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üß± Rebuild video from processed frames\n",
    "output_name = \"output.mp4\"\n",
    "(\n",
    "    ffmpeg\n",
    "    .input('output_frames/frame_%05d.png', framerate=30)\n",
    "    .output(output_name, vcodec='libx264', pix_fmt='yuv420p')\n",
    "    .run()\n",
    ")\n",
    "from IPython.display import Video\n",
    "Video(output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection ‚Äî What could be improved?\n",
    "\n",
    "| Limitation | Possible solution |\n",
    "|---|---|\n",
    "| Flickering (no temporal consistency) | Propagate the previous frame's mask via optical flow to constrain the current prediction |\n",
    "| Slow per-frame inference | Batch frames through the model; use GPU via `onnxruntime-gpu` |\n",
    "| Black background in output | Export as WebM with alpha channel, or composite over a custom background |\n",
    "| U2Net struggles with complex edges | Try `birefnet-general` (a newer, higher-quality model available in rembg) |\n",
    "| Hard mask edges | `rembg` supports matting post-processing (`om=True`) for softer transitions |\n",
    "\n",
    "These are the problems that production tools like DaVinci Resolve, Adobe After Effects, and cloud APIs solve ‚Äî each with their own trade-offs between speed, quality, and cost."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
